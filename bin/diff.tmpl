#! /bin/bash -l
#SBATCH --export=NONE
#SBATCH -M zeus
#SBATCH -p workq
#SBATCH --account=mwasci
#SBATCH --time=00:20:00
#SBATCH --nodes=1

base=BASEDIR
datadir="${base}/processing"
obsnum=OBSNUM

# import the tag and test_fail functions
. ${base}/bin/functions.sh

# setup a clean environment
source /group/mwa/software/module-reset.sh
module use /group/mwa/software/modulefiles
module load python
module load astropy
module list

set -x

# turn on timestamps
{

#memory in GB
mem=$(get_mem)
# number of cores
cores=$(get_cores)

cd ${datadir}

# start download
cd ${base}
python bin/track_task.py start --jobid=${SLURM_JOBID} --start_time=`date +%s`

cd ${datadir}/${obsnum}

# determine which files need to be diff-ed
files=(`ls -v ${obsnum}-0.5s-t*-pbcorr-I.fits`)
nfiles=${#files[@]}

for (( i=1; i<${nfiles}; i++ ))
do
  # run jobs in groups of N=${cores}
  ((j=j%${cores})); ((j++==0)) && wait
  # extract the time stamp id from thesecond file
  #id2=`echo ${files[i-1]} | sed "s/${obsnum}-0.5s-\(t????\)-pbcorr-I.fits/\1/g"`
  id2i=`echo ${files[i-1]} | awk -F'[-]' '{print $3"-"$4}'`
  outfile=`echo "${files[i]%%-pbcorr-I.fits}-${id2i}-pbcorr-I_diff.fits"`
  python ${base}/bin/fitssub.py ${files[i]} ${files[i-1]} ${outfile} &
done
# pause for all remaining jobs to complete
wait
test_fail $?

cd ${base}
python bin/track_task.py finish --jobid=${SLURM_JOBID} --finish_time=`date +%s`
} 2> >(awk '{print strftime("%F %T")";",$0; fflush()}' >&2) \
  1> >(awk '{print strftime("%F %T")";",$0; fflush()}')
